{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import math\n",
    "import gc\n",
    "import torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>video</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>orth</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-1</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-1/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>__ON__ JETZT WETTER MORGEN DONNERSTAG ZWOELF F...</td>\n",
       "      <td>und nun die wettervorhersage für morgen donner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-4</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-4/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>ORT-PLUSPLUS REGEN DURCH REGEN-PLUSPLUS KOENNE...</td>\n",
       "      <td>mancherorts regnet es auch länger und ergiebig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-5</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-5/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>__ON__ loc-NORDWEST HEUTE NACHT TROCKEN BLEIBE...</td>\n",
       "      <td>im nordwesten bleibt es heute nacht meist troc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-6</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-6/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>TAGSUEBER OFT REGEN-PLUSPLUS GEWITTER GEWITTER...</td>\n",
       "      <td>auch am tag gibt es verbreitet zum teil kräfti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-7</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-7/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>__ON__ WOLKE LOCH LOCH SPEZIELL loc-NORDWEST _...</td>\n",
       "      <td>größere wolkenlücken finden sich vor allem im ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  \\\n",
       "0  11August_2010_Wednesday_tagesschau-1   \n",
       "1  11August_2010_Wednesday_tagesschau-4   \n",
       "2  11August_2010_Wednesday_tagesschau-5   \n",
       "3  11August_2010_Wednesday_tagesschau-6   \n",
       "4  11August_2010_Wednesday_tagesschau-7   \n",
       "\n",
       "                                          video  start  end   speaker  \\\n",
       "0  11August_2010_Wednesday_tagesschau-1/1/*.png     -1   -1  Signer08   \n",
       "1  11August_2010_Wednesday_tagesschau-4/1/*.png     -1   -1  Signer08   \n",
       "2  11August_2010_Wednesday_tagesschau-5/1/*.png     -1   -1  Signer08   \n",
       "3  11August_2010_Wednesday_tagesschau-6/1/*.png     -1   -1  Signer08   \n",
       "4  11August_2010_Wednesday_tagesschau-7/1/*.png     -1   -1  Signer08   \n",
       "\n",
       "                                                orth  \\\n",
       "0  __ON__ JETZT WETTER MORGEN DONNERSTAG ZWOELF F...   \n",
       "1  ORT-PLUSPLUS REGEN DURCH REGEN-PLUSPLUS KOENNE...   \n",
       "2  __ON__ loc-NORDWEST HEUTE NACHT TROCKEN BLEIBE...   \n",
       "3  TAGSUEBER OFT REGEN-PLUSPLUS GEWITTER GEWITTER...   \n",
       "4  __ON__ WOLKE LOCH LOCH SPEZIELL loc-NORDWEST _...   \n",
       "\n",
       "                                         translation  \n",
       "0  und nun die wettervorhersage für morgen donner...  \n",
       "1  mancherorts regnet es auch länger und ergiebig...  \n",
       "2  im nordwesten bleibt es heute nacht meist troc...  \n",
       "3  auch am tag gibt es verbreitet zum teil kräfti...  \n",
       "4  größere wolkenlücken finden sich vor allem im ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/manual/PHOENIX-2014-T.train-complex-annotation.corpus.csv'\n",
    "dataframe = pd.read_csv(path, sep='|')\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>video</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>orth</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7086</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8827</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8827/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>__ON__ MONTAG MORGEN ACHT ZWANZIG JANUAR __OFF__</td>\n",
       "      <td>und nun die wettervorhersage für morgen montag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7087</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8830</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8830/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>__ON__ IN-KOMMEND WARM WIE PASSEN FRUEHLING NU...</td>\n",
       "      <td>in den nächsten tagen dann bei fast schon früh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7088</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8831</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8831/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>__ON__ HEUTE NACHT REGION SCHNEE SCHNEE REGEN ...</td>\n",
       "      <td>heute nacht gibt es im osten und süden noch sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7089</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8832</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8832/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>__ON__ BESONDERS NORD NORDWESTRAUM WOLKE VERSC...</td>\n",
       "      <td>vor allem im norden und westen klart es gebiet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7090</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8837</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8837/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>MORGEN TATSAECHLICH FROST negalp-KEIN EINS __H...</td>\n",
       "      <td>morgen seit längerem wieder frostfrei ein grad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7091</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8838</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8838/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>__ON__ DIENSTAG WIND STARK __HOLD__ REGEN __LE...</td>\n",
       "      <td>am dienstag wird es sehr windig und es regnet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7092</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8839</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8839/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>MITTWOCH WIND MEHR REGEN REGEN __PU__</td>\n",
       "      <td>am mittwoch legt der wind noch zu und es regne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7093</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8840</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8840/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>SUED REGION __HOLD__ SONNE AUCH DABEI</td>\n",
       "      <td>im süden zeigt sich aber auch die sonne .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7094</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8841</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8841/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>DONNERSTAG FREUNDLICH SONNE DANN SPAETER cl-KO...</td>\n",
       "      <td>der donnerstag beginnt oft freundlich später z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7095</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8842</td>\n",
       "      <td>27January_2013_Sunday_tagesschau-8842/1/*.png</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Signer01</td>\n",
       "      <td>__ON__ BLEIBEN WIND __OFF__</td>\n",
       "      <td>es bleibt windig .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name  \\\n",
       "7086  27January_2013_Sunday_tagesschau-8827   \n",
       "7087  27January_2013_Sunday_tagesschau-8830   \n",
       "7088  27January_2013_Sunday_tagesschau-8831   \n",
       "7089  27January_2013_Sunday_tagesschau-8832   \n",
       "7090  27January_2013_Sunday_tagesschau-8837   \n",
       "7091  27January_2013_Sunday_tagesschau-8838   \n",
       "7092  27January_2013_Sunday_tagesschau-8839   \n",
       "7093  27January_2013_Sunday_tagesschau-8840   \n",
       "7094  27January_2013_Sunday_tagesschau-8841   \n",
       "7095  27January_2013_Sunday_tagesschau-8842   \n",
       "\n",
       "                                              video  start  end   speaker  \\\n",
       "7086  27January_2013_Sunday_tagesschau-8827/1/*.png     -1   -1  Signer01   \n",
       "7087  27January_2013_Sunday_tagesschau-8830/1/*.png     -1   -1  Signer01   \n",
       "7088  27January_2013_Sunday_tagesschau-8831/1/*.png     -1   -1  Signer01   \n",
       "7089  27January_2013_Sunday_tagesschau-8832/1/*.png     -1   -1  Signer01   \n",
       "7090  27January_2013_Sunday_tagesschau-8837/1/*.png     -1   -1  Signer01   \n",
       "7091  27January_2013_Sunday_tagesschau-8838/1/*.png     -1   -1  Signer01   \n",
       "7092  27January_2013_Sunday_tagesschau-8839/1/*.png     -1   -1  Signer01   \n",
       "7093  27January_2013_Sunday_tagesschau-8840/1/*.png     -1   -1  Signer01   \n",
       "7094  27January_2013_Sunday_tagesschau-8841/1/*.png     -1   -1  Signer01   \n",
       "7095  27January_2013_Sunday_tagesschau-8842/1/*.png     -1   -1  Signer01   \n",
       "\n",
       "                                                   orth  \\\n",
       "7086   __ON__ MONTAG MORGEN ACHT ZWANZIG JANUAR __OFF__   \n",
       "7087  __ON__ IN-KOMMEND WARM WIE PASSEN FRUEHLING NU...   \n",
       "7088  __ON__ HEUTE NACHT REGION SCHNEE SCHNEE REGEN ...   \n",
       "7089  __ON__ BESONDERS NORD NORDWESTRAUM WOLKE VERSC...   \n",
       "7090  MORGEN TATSAECHLICH FROST negalp-KEIN EINS __H...   \n",
       "7091  __ON__ DIENSTAG WIND STARK __HOLD__ REGEN __LE...   \n",
       "7092              MITTWOCH WIND MEHR REGEN REGEN __PU__   \n",
       "7093              SUED REGION __HOLD__ SONNE AUCH DABEI   \n",
       "7094  DONNERSTAG FREUNDLICH SONNE DANN SPAETER cl-KO...   \n",
       "7095                        __ON__ BLEIBEN WIND __OFF__   \n",
       "\n",
       "                                            translation  \n",
       "7086  und nun die wettervorhersage für morgen montag...  \n",
       "7087  in den nächsten tagen dann bei fast schon früh...  \n",
       "7088  heute nacht gibt es im osten und süden noch sc...  \n",
       "7089  vor allem im norden und westen klart es gebiet...  \n",
       "7090  morgen seit längerem wieder frostfrei ein grad...  \n",
       "7091  am dienstag wird es sehr windig und es regnet ...  \n",
       "7092  am mittwoch legt der wind noch zu und es regne...  \n",
       "7093          im süden zeigt sich aber auch die sonne .  \n",
       "7094  der donnerstag beginnt oft freundlich später z...  \n",
       "7095                                 es bleibt windig .  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Signer01', 'Signer02', 'Signer03', 'Signer04', 'Signer05',\n",
       "       'Signer06', 'Signer07', 'Signer08', 'Signer09'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataframe['speaker'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop(columns=['start', 'end'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>video</th>\n",
       "      <th>speaker</th>\n",
       "      <th>orth</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-1</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-1/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>__ON__ JETZT WETTER MORGEN DONNERSTAG ZWOELF F...</td>\n",
       "      <td>und nun die wettervorhersage für morgen donner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-4</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-4/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>ORT-PLUSPLUS REGEN DURCH REGEN-PLUSPLUS KOENNE...</td>\n",
       "      <td>mancherorts regnet es auch länger und ergiebig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-5</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-5/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>__ON__ loc-NORDWEST HEUTE NACHT TROCKEN BLEIBE...</td>\n",
       "      <td>im nordwesten bleibt es heute nacht meist troc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-6</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-6/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>TAGSUEBER OFT REGEN-PLUSPLUS GEWITTER GEWITTER...</td>\n",
       "      <td>auch am tag gibt es verbreitet zum teil kräfti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-7</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-7/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>__ON__ WOLKE LOCH LOCH SPEZIELL loc-NORDWEST _...</td>\n",
       "      <td>größere wolkenlücken finden sich vor allem im ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-9</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-9/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>FLUSS HEUTE NACHT SECHS FLUSS SIEBZEHN GRAD</td>\n",
       "      <td>im emsland heute nacht nur neun am oberrhein b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-10</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-10/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>MORGEN TEMPERATUR GLEICH-WIE HEUTE NEUNZEHN BI...</td>\n",
       "      <td>morgen ähnliche temperaturen wie heute neunzeh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-11</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-11/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>__ON__ FREITAG loc-OST KOENNEN REGEN REGEN STA...</td>\n",
       "      <td>am freitag kann es in der osthälfte teilweise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-12</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-12/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>loc-REGION WECHSELHAFT REGEN GEWITTER AUCH WOC...</td>\n",
       "      <td>sonst wechselhaft mit schauern und gewittern d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-13</td>\n",
       "      <td>11August_2010_Wednesday_tagesschau-13/1/*.png</td>\n",
       "      <td>Signer08</td>\n",
       "      <td>__ON__ TEMPERATUR BLEIBEN GLEICH __OFF__</td>\n",
       "      <td>am temperaturniveau ändert sich wenig .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name  \\\n",
       "0   11August_2010_Wednesday_tagesschau-1   \n",
       "1   11August_2010_Wednesday_tagesschau-4   \n",
       "2   11August_2010_Wednesday_tagesschau-5   \n",
       "3   11August_2010_Wednesday_tagesschau-6   \n",
       "4   11August_2010_Wednesday_tagesschau-7   \n",
       "5   11August_2010_Wednesday_tagesschau-9   \n",
       "6  11August_2010_Wednesday_tagesschau-10   \n",
       "7  11August_2010_Wednesday_tagesschau-11   \n",
       "8  11August_2010_Wednesday_tagesschau-12   \n",
       "9  11August_2010_Wednesday_tagesschau-13   \n",
       "\n",
       "                                           video   speaker  \\\n",
       "0   11August_2010_Wednesday_tagesschau-1/1/*.png  Signer08   \n",
       "1   11August_2010_Wednesday_tagesschau-4/1/*.png  Signer08   \n",
       "2   11August_2010_Wednesday_tagesschau-5/1/*.png  Signer08   \n",
       "3   11August_2010_Wednesday_tagesschau-6/1/*.png  Signer08   \n",
       "4   11August_2010_Wednesday_tagesschau-7/1/*.png  Signer08   \n",
       "5   11August_2010_Wednesday_tagesschau-9/1/*.png  Signer08   \n",
       "6  11August_2010_Wednesday_tagesschau-10/1/*.png  Signer08   \n",
       "7  11August_2010_Wednesday_tagesschau-11/1/*.png  Signer08   \n",
       "8  11August_2010_Wednesday_tagesschau-12/1/*.png  Signer08   \n",
       "9  11August_2010_Wednesday_tagesschau-13/1/*.png  Signer08   \n",
       "\n",
       "                                                orth  \\\n",
       "0  __ON__ JETZT WETTER MORGEN DONNERSTAG ZWOELF F...   \n",
       "1  ORT-PLUSPLUS REGEN DURCH REGEN-PLUSPLUS KOENNE...   \n",
       "2  __ON__ loc-NORDWEST HEUTE NACHT TROCKEN BLEIBE...   \n",
       "3  TAGSUEBER OFT REGEN-PLUSPLUS GEWITTER GEWITTER...   \n",
       "4  __ON__ WOLKE LOCH LOCH SPEZIELL loc-NORDWEST _...   \n",
       "5        FLUSS HEUTE NACHT SECHS FLUSS SIEBZEHN GRAD   \n",
       "6  MORGEN TEMPERATUR GLEICH-WIE HEUTE NEUNZEHN BI...   \n",
       "7  __ON__ FREITAG loc-OST KOENNEN REGEN REGEN STA...   \n",
       "8  loc-REGION WECHSELHAFT REGEN GEWITTER AUCH WOC...   \n",
       "9           __ON__ TEMPERATUR BLEIBEN GLEICH __OFF__   \n",
       "\n",
       "                                         translation  \n",
       "0  und nun die wettervorhersage für morgen donner...  \n",
       "1  mancherorts regnet es auch länger und ergiebig...  \n",
       "2  im nordwesten bleibt es heute nacht meist troc...  \n",
       "3  auch am tag gibt es verbreitet zum teil kräfti...  \n",
       "4  größere wolkenlücken finden sich vor allem im ...  \n",
       "5  im emsland heute nacht nur neun am oberrhein b...  \n",
       "6  morgen ähnliche temperaturen wie heute neunzeh...  \n",
       "7  am freitag kann es in der osthälfte teilweise ...  \n",
       "8  sonst wechselhaft mit schauern und gewittern d...  \n",
       "9            am temperaturniveau ändert sich wenig .  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11August_2010_Wednesday_tagesschau-1/1/*.png'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['video'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "signer1_dataframe = dataframe[dataframe['speaker']=='Signer01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/transformers/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "signer1_dataframe.drop(columns=['speaker', 'video', 'translation'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>orth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>25October_2010_Monday_tagesschau-14</td>\n",
       "      <td>__ON__ __HOLD__ MORGEN WETTER WIE-AUSSEHEN DIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>25October_2010_Monday_tagesschau-15</td>\n",
       "      <td>__ON__ ITALIEN IX TIEF DRUCK cl-KOMMEN HEUTE N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>25October_2010_Monday_tagesschau-16</td>\n",
       "      <td>__ON__ LANG ZEIT __LEFTHAND__ REGION HOCH cl-K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>25October_2010_Monday_tagesschau-18</td>\n",
       "      <td>__ON__ TAG MISCHUNG SONNE WOLKE KOENNEN NEBEL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>25October_2010_Monday_tagesschau-19</td>\n",
       "      <td>WIND WEHEN WEHEN __LEFTHAND__ __OFF__ __ON__ A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>25October_2010_Monday_tagesschau-20</td>\n",
       "      <td>__ON__ HEUTE NACHT SECHS GRAD NORDRAUM MINUS S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>25October_2010_Monday_tagesschau-21</td>\n",
       "      <td>__ON__ DREI REGION DREI __HOLD__ ELF REGION __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>25October_2010_Monday_tagesschau-23</td>\n",
       "      <td>__ON__ REGION WOLKE NEBEL __LEFTHAND__ UND SON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>10March_2011_Thursday_heute-49</td>\n",
       "      <td>__ON__ GUT ABEND LIEB ZUSCHAUER poss-EUCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>10March_2011_Thursday_heute-50</td>\n",
       "      <td>WETTER WIND MORGEN VERSCHWINDEN DANN IN-KOMMEN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  \\\n",
       "10  25October_2010_Monday_tagesschau-14   \n",
       "11  25October_2010_Monday_tagesschau-15   \n",
       "12  25October_2010_Monday_tagesschau-16   \n",
       "13  25October_2010_Monday_tagesschau-18   \n",
       "14  25October_2010_Monday_tagesschau-19   \n",
       "15  25October_2010_Monday_tagesschau-20   \n",
       "16  25October_2010_Monday_tagesschau-21   \n",
       "17  25October_2010_Monday_tagesschau-23   \n",
       "37       10March_2011_Thursday_heute-49   \n",
       "38       10March_2011_Thursday_heute-50   \n",
       "\n",
       "                                                 orth  \n",
       "10  __ON__ __HOLD__ MORGEN WETTER WIE-AUSSEHEN DIE...  \n",
       "11  __ON__ ITALIEN IX TIEF DRUCK cl-KOMMEN HEUTE N...  \n",
       "12  __ON__ LANG ZEIT __LEFTHAND__ REGION HOCH cl-K...  \n",
       "13  __ON__ TAG MISCHUNG SONNE WOLKE KOENNEN NEBEL ...  \n",
       "14  WIND WEHEN WEHEN __LEFTHAND__ __OFF__ __ON__ A...  \n",
       "15  __ON__ HEUTE NACHT SECHS GRAD NORDRAUM MINUS S...  \n",
       "16  __ON__ DREI REGION DREI __HOLD__ ELF REGION __...  \n",
       "17  __ON__ REGION WOLKE NEBEL __LEFTHAND__ UND SON...  \n",
       "37          __ON__ GUT ABEND LIEB ZUSCHAUER poss-EUCH  \n",
       "38  WETTER WIND MORGEN VERSCHWINDEN DANN IN-KOMMEN...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signer1_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1862, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signer1_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1489,), (187,), (186,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(signer1_dataframe['orth'], test_size = 0.2, random_state = 42)\n",
    "val, test = train_test_split(test, test_size = 0.5, random_state = 42)\n",
    "train.shape, test.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['__ON__ __HOLD__ MORGEN WETTER WIE-AUSSEHEN DIENSTAG SECHS ZWANZIG OKTOBER __OFF__',\n",
       "       '__ON__ ITALIEN IX TIEF DRUCK cl-KOMMEN HEUTE NACHT BERG SCHNEE REGEN REGEN __OFF__',\n",
       "       '__ON__ LANG ZEIT __LEFTHAND__ REGION HOCH cl-KOMMEN OST cl-KOMMEN __HOLD__ SONST REGION DEUTSCH STARK RUHIG AUCH TEILWEISE FREUNDLICH SONNE __OFF__',\n",
       "       '__ON__ TAG MISCHUNG SONNE WOLKE KOENNEN NEBEL SUEDOSTRAUM SUED NORD HABEN SCHAUER SCHAUER KOENNEN ABEND DANN NORDWESTRAUM BISSCHEN WOLKE cl-KOMMEN',\n",
       "       'WIND WEHEN WEHEN __LEFTHAND__ __OFF__ __ON__ ABEND FRISCH WEHEN __OFF__',\n",
       "       '__ON__ HEUTE NACHT SECHS GRAD NORDRAUM MINUS SECHS ALLGAEU REGION __OFF__',\n",
       "       '__ON__ DREI REGION DREI __HOLD__ ELF REGION __OFF__',\n",
       "       '__ON__ REGION WOLKE NEBEL __LEFTHAND__ UND SONNE __OFF__',\n",
       "       '__ON__ GUT ABEND LIEB ZUSCHAUER poss-EUCH',\n",
       "       'WETTER WIND MORGEN VERSCHWINDEN DANN IN-KOMMEND WOCHENENDE LANGSAM KOMMEN KOMMEN FRUEHLING BODEN BLUETE BLUETE VORHER WOLKE BRAUN __OFF__'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(signer1_dataframe['orth'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:  __ON__ ITALIEN IX TIEF DRUCK cl-KOMMEN HEUTE NACHT BERG SCHNEE REGEN REGEN __OFF__\n",
      "encoded:  tensor([ 5, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 14,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "decoded:  __ON__ ITALIEN IX TIEF DRUCK cl-KOMMEN HEUTE NACHT BERG SCHNEE REGEN REGEN __OFF__ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "from torchnlp.encoders.text import StaticTokenizerEncoder, SpacyEncoder, pad_tensor\n",
    "loaded_data = np.array(signer1_dataframe['orth'])\n",
    "encoder = StaticTokenizerEncoder(loaded_data, tokenize=lambda s: s.split())\n",
    "\n",
    "encoded_data = [encoder.encode(example) for example in loaded_data]\n",
    "encoded_data = [pad_tensor(x, length=35) for x in encoded_data]\n",
    "\n",
    "example_encode = encoder.encode(loaded_data[1])\n",
    "example_pad = pad_tensor(example_encode, length=35)\n",
    "\n",
    "# print(encoded_data[:10])\n",
    "\n",
    "# print ()\n",
    "\n",
    "print('actual: ', loaded_data[1])\n",
    "print('encoded: ',example_pad)\n",
    "print('decoded: ', encoder.decode(example_pad))\n",
    "\n",
    "\n",
    "# encoder2 = SpacyEncoder(loaded_data)\n",
    "# encoded_data2 = [encoder2.encode(example) for example in loaded_data]\n",
    "# encoded_data2 = [pad_tensor(x, length=50)for x in encoded_data2]\n",
    "\n",
    "\n",
    "# print (encoded_data2[:10])\n",
    "\n",
    "\n",
    "# print('actual: ', loaded_data[1])\n",
    "# print('encoded: ', encoder2.encode(loaded_data[1]))\n",
    "# print('decoded: ', encoder2.decode(encoder2.encode(loaded_data[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy Tokenizer (Not in use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.tokenizer import Tokenizer\n",
    "# from spacy.lang.de import German\n",
    "# nlp = German()\n",
    "# # Create a blank Tokenizer with just the English vocab\n",
    "# tokenizer = nlp.Defaults.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchtext\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "# TEXT = torchtext.data.Field(tokenize = tokenizer,\n",
    "# #                             tokenizer_language=\"de\",\n",
    "#                             init_token = '<sos>',\n",
    "#                             eos_token = '<eos>',\n",
    "#                             lower = True)\n",
    "\n",
    "# TEXT.build_vocab(train)\n",
    "# print (TEXT.vocab.itos)\n",
    "# print (TEXT.vocab.stoi)\n",
    "\n",
    "#train_txt, val_txt, test_txt = torchtext.datasets.WikiText2.splits(TEXT)\n",
    "# TEXT.build_vocab(train_txt)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# def batchify(data, bsz):\n",
    "#     data = TEXT.numericalize([data.examples[0].text])\n",
    "#     # Divide the dataset into bsz parts.\n",
    "#     nbatch = data.size(0) // bsz\n",
    "#     # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "#     data = data.narrow(0, 0, nbatch * bsz)\n",
    "#     # Evenly divide the data across the bsz batches.\n",
    "#     data = data.view(bsz, -1).t().contiguous()\n",
    "#     return data.to(device)\n",
    "\n",
    "# batch_size = 20\n",
    "# eval_batch_size = 10\n",
    "# train_data = batchify(train_txt, batch_size)\n",
    "# val_data = batchify(val_txt, eval_batch_size)\n",
    "# test_data = batchify(test_txt, eval_batch_size)\n",
    "\n",
    "\n",
    "# print(type(train_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP = spacy.load('de_core_news_lg')\n",
    "# MAX_CHARS = 20000\n",
    "\n",
    "# !python -m spacy download de_core_news_lg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision.transforms import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor()])\n",
    "image_path = '../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px/train/01April_2010_Thursday_heute-6694/images0010.png'\n",
    "image = Image.open(image_path)\n",
    "image = transform(image)\n",
    "image = image.view(1, 3, 224,224)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of sequence sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = 0\n",
    "# max_folder = ''\n",
    "# list_folders = []\n",
    "# list_len = []\n",
    "\n",
    "# for folder in os.listdir('../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px/train/'):\n",
    "#     l = len(os.listdir('../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px/train/' + folder))\n",
    "#     list_folders.append(folder)\n",
    "#     list_len.append(l)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAX\n",
    "# print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(list(zip(list_folders, list_len)), columns=['Folder', 'No. of images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(df['No. of images'], bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signer1_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signer 1 alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1862/1862 [00:00<00:00, 8805.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1286, 2), (276, 2), (276, 2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "signer1_path = '../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px/train/'\n",
    "signer1 = signer1_dataframe.copy(deep=True)\n",
    "for folder in tqdm(signer1['name']):\n",
    "    if len(os.listdir(signer1_path + folder))>250:\n",
    "        signer1_dataframe = signer1_dataframe[signer1_dataframe['name']!=folder]\n",
    "\n",
    "signer1_train, signer1_test = train_test_split(signer1_dataframe, test_size=0.3, random_state=42)\n",
    "signer1_test, signer1_val = train_test_split(signer1_test, test_size=0.5, random_state=42)\n",
    "\n",
    "signer1_train.shape, signer1_test.shape, signer1_val.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1838, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signer1_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLRT_Signer(Dataset):\n",
    "    \"\"\"SLRT dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_frame, root_dir, transform, tokenizer, pretrained_model):\n",
    "        self.images_frame = data_frame['name']\n",
    "        self.glosses = data_frame['orth']\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        global device\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        training_example = torch.zeros(250,1000)\n",
    "        for files in os.listdir(os.path.join(self.root_dir, self.images_frame.iloc[idx])):\n",
    "            img_name = self.root_dir + self.images_frame.iloc[idx] + '/' + files\n",
    "            image = Image.open(img_name)\n",
    "            image = self.transform(image)\n",
    "            image = image.view(1, 3, 224,224)\n",
    "#             image = image.to(device)\n",
    "            vector = self.pretrained_model(image)\n",
    "            training_example[0:len(files), :] = vector\n",
    "            #can we preallocate tensor and add image encoding vector like tensor[:,0:image_size]\n",
    "        gloss = self.glosses.iloc[idx]\n",
    "        encoded_gloss = self.tokenizer.encode(gloss)\n",
    "        encoded_gloss = pad_tensor(encoded_gloss, 250)\n",
    "        #should we transform glosses to tokenized version before we form as training set??\n",
    "        #gloss = torch.tensor([gloss])\n",
    "        #landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        return training_example, encoded_gloss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify exisiting class to iterate through different samples using dataloader below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor()])\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "for param in model.parameters():    \n",
    "    param.requires_grad = False\n",
    "    \n",
    "# model.to(device)\n",
    "signer1_train_dataset = SLRT_Signer(signer1_train,\n",
    "                   root_dir='../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px/train/',\n",
    "                   transform=transform,\n",
    "                   tokenizer=encoder,\n",
    "                   pretrained_model = model)\n",
    "                  \n",
    "\n",
    "signer1_test_dataset = SLRT_Signer(signer1_test,\n",
    "                   root_dir='../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px/train/',\n",
    "                   transform=transform,\n",
    "                   tokenizer=encoder,\n",
    "                   pretrained_model = model)\n",
    "\n",
    "\n",
    "signer1_val_dataset = SLRT_Signer(signer1_val,\n",
    "                   root_dir='../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px/train/',\n",
    "                   transform=transform,\n",
    "                   tokenizer=encoder,\n",
    "                   pretrained_model = model)\n",
    "    \n",
    "# print (signer1_dataset.__len__())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 6,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "train_gen = DataLoader(signer1_train_dataset, **params)\n",
    "test_gen = DataLoader(signer1_test_dataset, **params)\n",
    "# val_gen = DataLoader(signer1_val_dataset, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _generate_square_subsequent_mask(self, src, trt, sz):\n",
    "# #         mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "# #         mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "# #         print (src.shape)\n",
    "#         mask = (torch.triu(torch.ones(sz, sz))==1).transpose(0,1)\n",
    "#         nopeak_mask = (mask==1).to(device)\n",
    "#         zeros = torch.zeros(1000).to(device)\n",
    "        \n",
    "#         target_msk = (trt[1] != 0).unsqueeze(1).to(device)\n",
    "#         target_msk = target_msk & nopeak_mask\n",
    "#         return src_msk, target_msk, nopeak_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.tensor([[1,2,3],[4,5,6],[0,0,0]])\n",
    "# print (x!=torch.tensor([0,0,0]).unsqueeze(0).transpose(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile Net Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet_mod = models.mobilenet_v2(pretrained=True)\n",
    "# for layer in mobilenet_mod.named_children():\n",
    "#     print (layer)\n",
    "# print (mobilenet_mod.classifier[1].out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MobileNetFinalLayer(nn.Module):\n",
    "#     def __init__(self, input_data, in_features, out_features, out_dim):\n",
    "#         super (MobileNetFinalLayer, self).__init__()\n",
    "#         self.mobilenet_model = models.mobilenet_v2(pretrained=True)\n",
    "#         self.input_data = input_data\n",
    "#         self.input_data_dim = input_data.shape\n",
    "#         self.final_layer_features =  in_features\n",
    "#         sefl.final_layer_linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "        \n",
    "#     def forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.tgt_mask = None\n",
    "        self.nopeakmask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "        #self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.decoder_embedding = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, src, trt, sz):\n",
    "#         mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "#         mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "#         print (src.shape)\n",
    "#         mask = (torch.triu(torch.ones(sz, sz))==1).transpose(0,1)\n",
    "#         nopeak_mask = (mask==0).to(device)\n",
    "#         nopeakmask = nn.Transformer.generate_square_subsequent_mask(self, sz).to(device)\n",
    "        mask = (torch.triu(torch.ones(250, 250)) == 1).transpose(0, 1).half().to(device)\n",
    "        nopeakmask = mask.float().half().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)).to(device)\n",
    "        zeros = torch.zeros(1000).half().to(device)\n",
    "        src_msk = (src == zeros).half().to(device)\n",
    "        target_msk = (trt == 0).unsqueeze(0).half().to(device)\n",
    "        #target_msk = target_msk & nopeak_mask\n",
    "        return src_msk, target_msk, nopeakmask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        #self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, trt):\n",
    "        \n",
    "        if self.src_mask is None or self.src_mask.size(0) != src.size(0):\n",
    "#             print (src.shape, trt.shape)\n",
    "            device = src.device\n",
    "            src_mask, tgt_mask, self.nopeakmask = self._generate_square_subsequent_mask(src, trt, src.size(1))\n",
    "#             print (src_mask.shape, tgt_mask.shape, nopeakmask.shape)\n",
    "            self.src_mask = src_mask\n",
    "            #self.tgt_mask = tgt_mask\n",
    "        #src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.permute(1,0,2)\n",
    "        trgt = self.decoder_embedding(trt)\n",
    "        trgt = trgt.permute(1,0,2)\n",
    "#         print (trgt.shape), print (output.shape)\n",
    "        output = self.transformer_decoder(trgt, output, tgt_mask = self.nopeakmask) #tgt_key_padding_mask = tgt_mask)\n",
    "        output = self.decoder(output)\n",
    "#         print (output.shape)\n",
    "        output = output.permute(1,2,0)\n",
    "        #output = output.reshape(-1, output.shape[2])\n",
    "#         output = self.softmax(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(encoder.vocab) # the size of vocabulary\n",
    "emsize = 1000 # embedding dimension\n",
    "nhid = 500 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "src_pad_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model training\n",
    "# transformer = TransformerModel(ntokens, emsize, nhid, nlayers,nhead, dropout).half().to(device)\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index = src_pad_index)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "#  # enumerate epochs\n",
    "# for epoch in range(10):\n",
    "# # enumerate mini batches\n",
    "#     epoch_loss = 0\n",
    "#     print (\"Epoch: \", epoch, \"in progress...\")\n",
    "#     for i, (inputs, targets) in enumerate(train_gen):   \n",
    "#         inputs, targets = inputs.half().to(device), targets.to(device)\n",
    "#         # clear the gradients\n",
    "#         optimizer.zero_grad()\n",
    "#         # compute the model output\n",
    "#         yhat = transformer(inputs, targets)\n",
    "#         # calculate loss\n",
    "#         loss = criterion(yhat, targets)\n",
    "#         # credit assignment\n",
    "#         loss.backward()\n",
    "#         # update model weights\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "#         torch.cuda.empty_cache()\n",
    "#         del inputs, targets\n",
    "#         gc.collect()\n",
    "#     print (\"Epoch {} : {}\".format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(epoch, epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-30f569a015a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m torch.save({\n\u001b[1;32m      2\u001b[0m             \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m             \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m448.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformer' is not defined"
     ]
    }
   ],
   "source": [
    "# torch.save({\n",
    "#             'epoch': 10,\n",
    "#             'model_state_dict': transformer.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': 448.1\n",
    "#             }, 'model-1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_model  = TransformerModel(ntokens, emsize, nhid, nlayers,nhead, dropout).half().to(device)\n",
    "eval_model  = TransformerModel(ntokens, emsize, nhid, nlayers,nhead, dropout).half().to(device)\n",
    "\n",
    "eval_optim = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load('model-1.pt')\n",
    "eval_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "eval_optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = src_pad_index)\n",
    "eval_model.eval()\n",
    "\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:22, 82.01s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 358.00 MiB (GPU 0; 7.79 GiB total capacity; 4.76 GiB already allocated; 100.19 MiB free; 86.43 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-4fb998803f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# compute the model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/transformers/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-eb99a792a971>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trt)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mtrgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#         print (trgt.shape), print (output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnopeakmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tgt_key_padding_mask = tgt_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#         print (output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/transformers/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/transformers/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                     \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                                     \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                                     memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/transformers/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/transformers/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m    324\u001b[0m         tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n\u001b[0;32m--> 325\u001b[0;31m                               key_padding_mask=tgt_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/transformers/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/transformers/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/transformers/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3245\u001b[0m                                                device=key_padding_mask.device)], dim=1)\n\u001b[1;32m   3246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3247\u001b[0;31m     \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3248\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 358.00 MiB (GPU 0; 7.79 GiB total capacity; 4.76 GiB already allocated; 100.19 MiB free; 86.43 MiB cached)"
     ]
    }
   ],
   "source": [
    "epoch_loss = 0\n",
    "for i, (inputs, targets) in tqdm(enumerate(test_gen)):   \n",
    "#     inputs, targets = inputs.half().to(device), targets.to(device)\n",
    "    inputs, targets = inputs.half(), targets\n",
    "    \n",
    "    # clear the gradients\n",
    "#     optimizer.zero_grad()\n",
    "    # compute the model output\n",
    "    yhat = eval_model(inputs, targets)\n",
    "    # calculate loss\n",
    "    loss = criterion(yhat, targets)\n",
    "    \n",
    "#     print(f\"Batch {i+1}\\nActual: {encoder.decode(targets.to(torch.device('cpu')).detach().numpy()[0])}\\nPredicted: {encoder.decode(yhat.to(torch.device('cpu')).detach().numpy()[0])}\")\n",
    "#     print(f\"Batch {i+1}\\nActual: {encoder.decode(targets(0))}\\nPredicted: {encoder.decode(yhat[0])}\")\n",
    "    \n",
    "    # credit assignment\n",
    "#     loss.backward()\n",
    "    # update model weights\n",
    "#     optimizer.step()\n",
    "    epoch_loss += loss.item()\n",
    "    torch.cuda.empty_cache()\n",
    "    del inputs, targets\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "print (\"Epoch {} : Batch Loss {}\".format(1, epoch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
